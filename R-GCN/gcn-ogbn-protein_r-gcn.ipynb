{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Install prerequisites"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport humanize\nstart_time = time.time()","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# install Open Graph Benchmark\n! pip install ogb\n\n# install PyTorch Geometric\n!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n!pip install torch-geometric","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting ogb\n  Downloading ogb-1.2.0-py3-none-any.whl (45 kB)\n\u001b[K     |████████████████████████████████| 45 kB 1.6 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (0.23.1)\nRequirement already satisfied: tqdm>=4.29.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (4.45.0)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.18.1)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.14.0)\nRequirement already satisfied: urllib3>=1.24.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.24.3)\nRequirement already satisfied: torch>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.5.0)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from ogb) (1.0.3)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->ogb) (0.14.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.0->ogb) (2.1.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.2.0->ogb) (0.18.2)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->ogb) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->ogb) (2019.3)\nInstalling collected packages: ogb\nSuccessfully installed ogb-1.2.0\nLooking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\nCollecting torch-scatter==latest+cu101\n  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_scatter-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.3 MB)\n\u001b[K     |████████████████████████████████| 12.3 MB 20.6 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.0.4\nLooking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\nCollecting torch-sparse==latest+cu101\n  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_sparse-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl (21.6 MB)\n\u001b[K     |████████████████████████████████| 21.6 MB 7.7 MB/s eta 0:00:01    |████████████▎                   | 8.3 MB 7.7 MB/s eta 0:00:02     |██████████████▍                 | 9.7 MB 7.7 MB/s eta 0:00:02\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torch-sparse==latest+cu101) (1.4.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scipy->torch-sparse==latest+cu101) (1.18.1)\nInstalling collected packages: torch-sparse\nSuccessfully installed torch-sparse-0.6.5\nLooking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\nCollecting torch-cluster==latest+cu101\n  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_cluster-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl (18.2 MB)\n\u001b[K     |████████████████████████████████| 18.2 MB 13.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torch-cluster==latest+cu101) (1.4.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scipy->torch-cluster==latest+cu101) (1.18.1)\nInstalling collected packages: torch-cluster\nSuccessfully installed torch-cluster-1.5.4\nLooking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\nCollecting torch-spline-conv==latest+cu101\n  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_spline_conv-latest%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.3 MB)\n\u001b[K     |████████████████████████████████| 6.3 MB 12.9 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: torch-spline-conv\nSuccessfully installed torch-spline-conv-1.2.0\nCollecting torch-geometric\n  Downloading torch_geometric-1.5.0.tar.gz (153 kB)\n\u001b[K     |████████████████████████████████| 153 kB 8.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (1.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (1.18.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (4.45.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (1.4.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (2.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (0.23.1)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (0.48.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (2.23.0)\nCollecting plyfile\n  Downloading plyfile-0.7.2-py3-none-any.whl (39 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (1.0.3)\nCollecting rdflib\n  Downloading rdflib-5.0.0-py3-none-any.whl (231 kB)\n\u001b[K     |████████████████████████████████| 231 kB 23.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (2.10.0)\nCollecting googledrivedownloader\n  Downloading googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\nCollecting ase\n  Downloading ase-3.19.1-py3-none-any.whl (2.1 MB)\n\u001b[K     |████████████████████████████████| 2.1 MB 22.7 MB/s eta 0:00:01     |███                             | 194 kB 22.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torch-geometric) (0.18.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->torch-geometric) (4.4.2)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torch-geometric) (0.14.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torch-geometric) (2.1.0)\nRequirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba->torch-geometric) (0.31.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->torch-geometric) (46.1.3.post20200325)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric) (2020.4.5.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric) (1.24.3)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->torch-geometric) (2019.3)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->torch-geometric) (2.8.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from rdflib->torch-geometric) (1.14.0)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from rdflib->torch-geometric) (2.4.7)\nCollecting isodate\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n\u001b[K     |████████████████████████████████| 45 kB 3.0 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from ase->torch-geometric) (3.2.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ase->torch-geometric) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ase->torch-geometric) (0.10.0)\nBuilding wheels for collected packages: torch-geometric\n","name":"stdout"},{"output_type":"stream","text":"  Building wheel for torch-geometric (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-1.5.0-py3-none-any.whl size=267915 sha256=90a10e4560e0bb58e9582efe3e2f09e6399d4aa7d4c1641c5c22890b193bea37\n  Stored in directory: /root/.cache/pip/wheels/87/09/84/1d026c4e02fc66af6224faaa7c35db83a178ec6593e69baf06\nSuccessfully built torch-geometric\nInstalling collected packages: plyfile, isodate, rdflib, googledrivedownloader, ase, torch-geometric\nSuccessfully installed ase-3.19.1 googledrivedownloader-0.4 isodate-0.6.0 plyfile-0.7.2 rdflib-5.0.0 torch-geometric-1.5.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom torch_sparse import SparseTensor\nfrom torch_scatter import scatter\nfrom torch_geometric.nn.inits import glorot, zeros\n\nfrom ogb.nodeproppred import PygNodePropPredDataset, Evaluator","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logger"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Logger(object):\n    def __init__(self, runs, info=None):\n        self.info = info\n        self.results = [[] for _ in range(runs)]\n\n    def add_result(self, run, result):\n        assert len(result) == 3\n        assert run >= 0 and run < len(self.results)\n        self.results[run].append(result)\n\n    def print_statistics(self, run=None):\n        if run is not None:\n            result = 100 * torch.tensor(self.results[run])\n            argmax = result[:, 1].argmax().item()\n            print(f'Run {run + 1:02d}:')\n            print(f'Highest Train: {result[:, 0].max():.2f}')\n            print(f'Highest Valid: {result[:, 1].max():.2f}')\n            print(f'  Final Train: {result[argmax, 0]:.2f}')\n            print(f'   Final Test: {result[argmax, 2]:.2f}')\n        else:\n            result = 100 * torch.tensor(self.results)\n\n            best_results = []\n            for r in result:\n                train1 = r[:, 0].max().item()\n                valid = r[:, 1].max().item()\n                train2 = r[r[:, 1].argmax(), 0].item()\n                test = r[r[:, 1].argmax(), 2].item()\n                best_results.append((train1, valid, train2, test))\n\n            best_result = torch.tensor(best_results)\n\n            print(f'All runs:')\n            r = best_result[:, 0]\n            print(f'Highest Train: {r.mean():.2f} ± {r.std():.2f}')\n            r = best_result[:, 1]\n            print(f'Highest Valid: {r.mean():.2f} ± {r.std():.2f}')\n            r = best_result[:, 2]\n            print(f'  Final Train: {r.mean():.2f} ± {r.std():.2f}')\n            r = best_result[:, 3]\n            print(f'   Final Test: {r.mean():.2f} ± {r.std():.2f}')","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"class args:\n    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n    log_steps = 1\n    num_layers = 3\n    skip_layers = 3\n    hidden_channels = 256\n    dropout = 0.05\n    lr = 0.005\n    epochs = 1000\n    eval_steps = 10\n    runs = 1","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(args.device)\n\ndataset = PygNodePropPredDataset(name='ogbn-proteins')\nsplit_idx = dataset.get_idx_split()\ndata = dataset[0]\n\nx = scatter(data.edge_attr, data.edge_index[0], dim=0,\n            dim_size=data.num_nodes, reduce='mean').to(device)\n\ny_true = data.y.to(device)\ntrain_idx = split_idx['train'].to(device)\n\nedge_index = data.edge_index.to(device)\nadj = SparseTensor(row=edge_index[0], col=edge_index[1])","execution_count":6,"outputs":[{"output_type":"stream","text":"Downloading https://snap.stanford.edu/ogb/data/nodeproppred/proteinfunc.zip\n","name":"stdout"},{"output_type":"stream","text":"Downloaded 0.21 GB: 100%|██████████| 216/216 [00:53<00:00,  4.03it/s]\n","name":"stderr"},{"output_type":"stream","text":"Extracting dataset/proteinfunc.zip\nProcessing...\nLoading necessary files...\nThis might take a while.\n","name":"stdout"},{"output_type":"stream","text":"\r  0%|          | 0/1 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Processing graphs...\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n100%|██████████| 1/1 [00:00<00:00, 240.18it/s]\n","name":"stderr"},{"output_type":"stream","text":"Converting graphs into PyG objects...\nSaving...\nDone!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(humanize.naturaldelta(start_time - time.time()))","execution_count":7,"outputs":[{"output_type":"stream","text":"4 minutes\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Model Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch_geometric.nn import DenseSAGEConv\nnormalize = True\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GCNConv(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(GCNConv, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n        self.bias = Parameter(torch.Tensor(out_channels))\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        glorot(self.weight)\n        zeros(self.bias)\n        \n\n    def forward(self, x, adj):\n        return adj @ x @ self.weight","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SAGEConv(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(SAGEConv, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n        self.root_weight = Parameter(torch.Tensor(in_channels, out_channels))\n        self.bias = Parameter(torch.Tensor(out_channels))\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        glorot(self.weight)\n        glorot(self.root_weight)\n        zeros(self.bias)\n\n    def forward(self, x, adj):\n        out = adj.matmul(x, reduce=\"mean\") @ self.weight\n        out = out + x @ self.root_weight + self.bias\n        return out","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResidualGC(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, skip_n_channels,dropout):\n        super(ResidualGC, self).__init__()\n        self.convs = torch.nn.ModuleList()\n        self.convs.append(GCNConv(in_channels, hidden_channels))\n        for _ in range(skip_n_channels):\n            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n        \n        self.compress = SAGEConv(hidden_channels + in_channels, hidden_channels)\n        \n        self.convs.append(GCNConv(hidden_channels, out_channels))\n        \n        self.dropout = dropout\n    \n    def reset_parameters(self):\n        for conv in self.convs:\n            conv.reset_parameters()\n        self.compress.reset_parameters()\n            \n    def forward(self, x, adj):\n        x_i = x #identity\n        for conv in self.convs[:-1]:\n            x = conv(x, adj)\n            x = F.relu(x)\n            x = F.dropout(x, p=self.dropout, training=self.training)\n\n        x = torch.cat([x_i,x],1)\n        \n        x = self.compress(x, adj)\n        x = self.convs[-1](x, adj)\n        return x\n    ","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GCN(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n                 dropout):\n        super(GCN, self).__init__()\n        self.init_conv = GCNConv(in_channels, hidden_channels)\n        self.res1 = ResidualGC(hidden_channels,hidden_channels, hidden_channels,3, dropout)    \n        self.bridge = GCNConv(hidden_channels, hidden_channels)     \n        self.res2 = ResidualGC(hidden_channels,hidden_channels, out_channels,3, dropout)\n        self.final_conv = GCNConv(out_channels, out_channels)    \n        self.dropout = dropout\n\n    def reset_parameters(self):\n        self.init_conv.reset_parameters()\n        self.res1.reset_parameters()\n        self.bridge.reset_parameters()\n        self.res2.reset_parameters()\n        self.final_conv.reset_parameters()\n\n    def forward(self, x, adj):\n        x = self.init_conv(x,adj)\n        x = self.res1(x,adj)\n        x = self.bridge(x,adj)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.res2(x,adj)\n        x = self.final_conv(x,adj)\n\n        return x","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RRGCN(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n                 dropout):\n        super(RRGCN, self).__init__()\n        self.init_conv = GCNConv(in_channels, hidden_channels)\n        self.res1 = ResidualGC(hidden_channels,hidden_channels, hidden_channels,3, dropout)    \n        self.bridge = GCNConv(hidden_channels, hidden_channels)     \n        self.res2 = ResidualGC(hidden_channels,hidden_channels, hidden_channels,3, dropout)\n        self.compress = GCNConv(hidden_channels*2, out_channels)\n        self.final_conv = GCNConv(out_channels, out_channels)    \n        self.dropout = dropout\n\n    def reset_parameters(self):\n        self.init_conv.reset_parameters()\n        self.res1.reset_parameters()\n        self.bridge.reset_parameters()\n        self.res2.reset_parameters()\n        self.final_conv.reset_parameters()\n\n    def forward(self, x, adj):\n        x = self.init_conv(x,adj)\n        x_i = x\n        x = self.res1(x,adj)\n        x = self.bridge(x,adj)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.res2(x,adj)\n        x = torch.cat([x,x_i],1) \n        x = self.final_conv(x,adj)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and eval"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, x, adj, y_true, train_idx, optimizer):\n    model.train()\n    criterion = torch.nn.BCEWithLogitsLoss()\n\n    optimizer.zero_grad()\n    out = model(x, adj)[train_idx]\n    loss = criterion(out, y_true[train_idx].to(torch.float))\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef test(model, x, adj, y_true, split_idx, evaluator):\n    model.eval()\n\n    y_pred = model(x, adj)\n\n    train_rocauc = evaluator.eval({\n        'y_true': y_true[split_idx['train']],\n        'y_pred': y_pred[split_idx['train']],\n    })['rocauc']\n    valid_rocauc = evaluator.eval({\n        'y_true': y_true[split_idx['valid']],\n        'y_pred': y_pred[split_idx['valid']],\n    })['rocauc']\n    test_rocauc = evaluator.eval({\n        'y_true': y_true[split_idx['test']],\n        'y_pred': y_pred[split_idx['test']],\n    })['rocauc']\n\n    return train_rocauc, valid_rocauc, test_rocauc","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = GCN(x.size(-1), args.hidden_channels, 112, args.num_layers,args.dropout).to(device)\n\n# model = ResidualGC(x.size(-1),args.hidden_channels,112,3,args.dropout).to(device)\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Pre-compute GCN normalization.\nadj = adj.set_diag()\ndeg = adj.sum(dim=1).to(torch.float)\ndeg_inv_sqrt = deg.pow(-0.5)\ndeg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\nadj = deg_inv_sqrt.view(-1, 1) * adj * deg_inv_sqrt.view(1, -1)\n    \nevaluator = Evaluator(name='ogbn-proteins')\nlogger = Logger(args.runs, args)\nbest_test_score = 0\n\nfor run in range(args.runs):\n    model.reset_parameters()\n    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n    for epoch in range(1, 1 + args.epochs):\n        \n        loss = train(model, x, adj, y_true, train_idx, optimizer)\n\n        if epoch % args.eval_steps == 0:\n            result = test(model, x, adj, y_true, split_idx, evaluator)\n            logger.add_result(run, result)\n\n            if epoch % args.log_steps == 0:                \n                train_rocauc, valid_rocauc, test_rocauc = result\n                print(f'Run: {run + 1:02d}\\t '\n                      f'Epoch: {epoch:02d}\\t '\n                      f'Loss: {loss:.4f}\\t '\n                      f'Train: {100 * train_rocauc:.2f}%\\t '\n                      f'Valid: {100 * valid_rocauc:.2f}%\\t'\n                      f'Test: {100 * test_rocauc:.2f}%')\n                if(test_rocauc > best_test_score):\n                    best_test_score = test_rocauc\n                    save_path = \"gcn_\" + f'Test: {100 * test_rocauc:.2f}' + \".pth\"\n                    torch.save(model, save_path)\n                    print(\"Model saved.\")\n\n    logger.print_statistics(run)\nlogger.print_statistics()","execution_count":19,"outputs":[{"output_type":"stream","text":"Run: 01\t Epoch: 10\t Loss: 0.5052\t Train: 54.04%\t Valid: 47.02%\tTest: 42.46%\nModel saved.\nRun: 01\t Epoch: 20\t Loss: 0.3479\t Train: 66.58%\t Valid: 58.08%\tTest: 50.57%\nModel saved.\nRun: 01\t Epoch: 30\t Loss: 0.3297\t Train: 69.02%\t Valid: 65.42%\tTest: 57.40%\nModel saved.\nRun: 01\t Epoch: 40\t Loss: 0.3230\t Train: 70.39%\t Valid: 67.40%\tTest: 61.99%\nModel saved.\nRun: 01\t Epoch: 50\t Loss: 0.3198\t Train: 71.48%\t Valid: 67.19%\tTest: 60.97%\nRun: 01\t Epoch: 60\t Loss: 0.3170\t Train: 72.22%\t Valid: 68.85%\tTest: 63.13%\nModel saved.\nRun: 01\t Epoch: 70\t Loss: 0.3118\t Train: 73.42%\t Valid: 70.66%\tTest: 61.53%\nRun: 01\t Epoch: 80\t Loss: 0.3070\t Train: 74.70%\t Valid: 71.81%\tTest: 64.32%\nModel saved.\nRun: 01\t Epoch: 90\t Loss: 0.3035\t Train: 75.97%\t Valid: 73.51%\tTest: 65.35%\nModel saved.\nRun: 01\t Epoch: 100\t Loss: 0.3092\t Train: 75.05%\t Valid: 72.72%\tTest: 67.62%\nModel saved.\nRun: 01\t Epoch: 110\t Loss: 0.3015\t Train: 76.45%\t Valid: 73.23%\tTest: 66.97%\nRun: 01\t Epoch: 120\t Loss: 0.2952\t Train: 77.83%\t Valid: 74.35%\tTest: 67.94%\nModel saved.\nRun: 01\t Epoch: 130\t Loss: 0.3041\t Train: 77.63%\t Valid: 74.10%\tTest: 64.90%\nRun: 01\t Epoch: 140\t Loss: 0.2926\t Train: 78.90%\t Valid: 74.55%\tTest: 66.72%\nRun: 01\t Epoch: 150\t Loss: 0.2943\t Train: 79.60%\t Valid: 75.29%\tTest: 66.07%\nRun: 01\t Epoch: 160\t Loss: 0.2866\t Train: 80.29%\t Valid: 76.15%\tTest: 70.04%\nModel saved.\nRun: 01\t Epoch: 170\t Loss: 0.3117\t Train: 68.92%\t Valid: 62.23%\tTest: 50.73%\nRun: 01\t Epoch: 180\t Loss: 0.3495\t Train: 68.82%\t Valid: 63.42%\tTest: 58.84%\nRun: 01\t Epoch: 190\t Loss: 0.3267\t Train: 72.04%\t Valid: 66.88%\tTest: 60.36%\nRun: 01\t Epoch: 200\t Loss: 0.3155\t Train: 73.75%\t Valid: 68.01%\tTest: 62.00%\nRun: 01\t Epoch: 210\t Loss: 0.3061\t Train: 75.25%\t Valid: 70.27%\tTest: 63.85%\nRun: 01\t Epoch: 220\t Loss: 0.3029\t Train: 76.46%\t Valid: 72.05%\tTest: 66.62%\nRun: 01\t Epoch: 230\t Loss: 0.3003\t Train: 77.45%\t Valid: 73.72%\tTest: 68.10%\nRun: 01\t Epoch: 240\t Loss: 0.2948\t Train: 78.68%\t Valid: 75.27%\tTest: 68.04%\nRun: 01\t Epoch: 250\t Loss: 0.3043\t Train: 76.38%\t Valid: 72.02%\tTest: 67.68%\nRun: 01\t Epoch: 260\t Loss: 0.2986\t Train: 77.73%\t Valid: 74.01%\tTest: 67.76%\nRun: 01\t Epoch: 270\t Loss: 0.2920\t Train: 79.29%\t Valid: 75.42%\tTest: 69.23%\nRun: 01\t Epoch: 280\t Loss: 0.2969\t Train: 79.36%\t Valid: 75.84%\tTest: 70.02%\nRun: 01\t Epoch: 290\t Loss: 0.2962\t Train: 78.62%\t Valid: 74.88%\tTest: 68.92%\nRun: 01\t Epoch: 300\t Loss: 0.2959\t Train: 79.21%\t Valid: 76.24%\tTest: 69.32%\nRun: 01\t Epoch: 310\t Loss: 0.2891\t Train: 79.80%\t Valid: 76.00%\tTest: 70.70%\nModel saved.\nRun: 01\t Epoch: 320\t Loss: 0.2839\t Train: 80.78%\t Valid: 77.09%\tTest: 68.82%\nRun: 01\t Epoch: 330\t Loss: 0.2898\t Train: 80.98%\t Valid: 77.24%\tTest: 69.91%\nRun: 01\t Epoch: 340\t Loss: 0.2902\t Train: 80.49%\t Valid: 77.16%\tTest: 70.16%\nRun: 01\t Epoch: 350\t Loss: 0.2808\t Train: 81.32%\t Valid: 77.46%\tTest: 71.01%\nModel saved.\nRun: 01\t Epoch: 360\t Loss: 0.3089\t Train: 76.11%\t Valid: 71.29%\tTest: 66.11%\nRun: 01\t Epoch: 370\t Loss: 0.2986\t Train: 78.20%\t Valid: 75.61%\tTest: 67.59%\nRun: 01\t Epoch: 380\t Loss: 0.2957\t Train: 79.31%\t Valid: 76.56%\tTest: 69.13%\nRun: 01\t Epoch: 390\t Loss: 0.2871\t Train: 80.61%\t Valid: 77.73%\tTest: 69.97%\nRun: 01\t Epoch: 400\t Loss: 0.2807\t Train: 81.49%\t Valid: 78.19%\tTest: 71.84%\nModel saved.\nRun: 01\t Epoch: 410\t Loss: 0.2914\t Train: 80.01%\t Valid: 76.93%\tTest: 70.02%\nRun: 01\t Epoch: 420\t Loss: 0.2823\t Train: 81.09%\t Valid: 77.68%\tTest: 71.17%\nRun: 01\t Epoch: 430\t Loss: 0.2904\t Train: 80.24%\t Valid: 76.94%\tTest: 72.85%\nModel saved.\nRun: 01\t Epoch: 440\t Loss: 0.2800\t Train: 81.40%\t Valid: 77.95%\tTest: 71.45%\nRun: 01\t Epoch: 450\t Loss: 0.2792\t Train: 82.10%\t Valid: 78.35%\tTest: 72.59%\nRun: 01\t Epoch: 460\t Loss: 0.2728\t Train: 82.78%\t Valid: 78.71%\tTest: 72.42%\nRun: 01\t Epoch: 470\t Loss: 0.2773\t Train: 81.75%\t Valid: 76.96%\tTest: 71.60%\nRun: 01\t Epoch: 480\t Loss: 0.2979\t Train: 79.12%\t Valid: 75.08%\tTest: 70.55%\nRun: 01\t Epoch: 490\t Loss: 0.2865\t Train: 80.52%\t Valid: 77.14%\tTest: 69.76%\nRun: 01\t Epoch: 500\t Loss: 0.2823\t Train: 81.16%\t Valid: 78.16%\tTest: 71.51%\nRun: 01\t Epoch: 510\t Loss: 0.2781\t Train: 82.20%\t Valid: 78.74%\tTest: 72.08%\nRun: 01\t Epoch: 520\t Loss: 0.2720\t Train: 83.00%\t Valid: 78.80%\tTest: 73.22%\nModel saved.\nRun: 01\t Epoch: 530\t Loss: 0.2866\t Train: 82.90%\t Valid: 79.02%\tTest: 71.82%\nRun: 01\t Epoch: 540\t Loss: 0.2734\t Train: 83.13%\t Valid: 78.90%\tTest: 72.74%\nRun: 01\t Epoch: 550\t Loss: 0.2772\t Train: 83.51%\t Valid: 79.02%\tTest: 72.77%\nRun: 01\t Epoch: 560\t Loss: 0.2665\t Train: 83.93%\t Valid: 79.42%\tTest: 72.81%\nRun: 01\t Epoch: 570\t Loss: 0.2678\t Train: 83.64%\t Valid: 79.05%\tTest: 73.56%\nModel saved.\nRun: 01\t Epoch: 580\t Loss: 0.2659\t Train: 83.72%\t Valid: 79.73%\tTest: 73.72%\nModel saved.\nRun: 01\t Epoch: 590\t Loss: 0.2702\t Train: 83.76%\t Valid: 79.03%\tTest: 73.42%\nRun: 01\t Epoch: 600\t Loss: 0.2684\t Train: 83.85%\t Valid: 79.62%\tTest: 73.07%\nRun: 01\t Epoch: 610\t Loss: 0.2695\t Train: 84.40%\t Valid: 80.04%\tTest: 73.07%\nRun: 01\t Epoch: 620\t Loss: 0.2606\t Train: 84.67%\t Valid: 80.27%\tTest: 73.11%\nRun: 01\t Epoch: 630\t Loss: 0.2596\t Train: 84.87%\t Valid: 80.37%\tTest: 73.32%\nRun: 01\t Epoch: 640\t Loss: 0.2758\t Train: 83.15%\t Valid: 78.39%\tTest: 71.44%\nRun: 01\t Epoch: 650\t Loss: 0.2689\t Train: 83.84%\t Valid: 79.59%\tTest: 72.78%\nRun: 01\t Epoch: 660\t Loss: 0.2645\t Train: 84.56%\t Valid: 80.44%\tTest: 74.38%\nModel saved.\nRun: 01\t Epoch: 670\t Loss: 0.2580\t Train: 85.25%\t Valid: 80.58%\tTest: 74.10%\nRun: 01\t Epoch: 680\t Loss: 0.2612\t Train: 85.54%\t Valid: 81.00%\tTest: 74.20%\nRun: 01\t Epoch: 690\t Loss: 0.2576\t Train: 85.49%\t Valid: 80.95%\tTest: 74.23%\nRun: 01\t Epoch: 700\t Loss: 0.2573\t Train: 85.45%\t Valid: 80.76%\tTest: 74.05%\nRun: 01\t Epoch: 710\t Loss: 0.2546\t Train: 85.93%\t Valid: 81.04%\tTest: 74.60%\nModel saved.\nRun: 01\t Epoch: 720\t Loss: 0.2562\t Train: 85.63%\t Valid: 80.65%\tTest: 74.90%\nModel saved.\nRun: 01\t Epoch: 730\t Loss: 0.2551\t Train: 85.68%\t Valid: 81.25%\tTest: 74.32%\nRun: 01\t Epoch: 740\t Loss: 0.2593\t Train: 85.72%\t Valid: 81.05%\tTest: 73.70%\nRun: 01\t Epoch: 750\t Loss: 0.2523\t Train: 86.08%\t Valid: 81.41%\tTest: 74.89%\nRun: 01\t Epoch: 760\t Loss: 0.2569\t Train: 86.34%\t Valid: 81.38%\tTest: 74.77%\nRun: 01\t Epoch: 770\t Loss: 0.2554\t Train: 86.18%\t Valid: 81.22%\tTest: 74.96%\nModel saved.\nRun: 01\t Epoch: 780\t Loss: 0.2515\t Train: 86.33%\t Valid: 81.54%\tTest: 74.68%\nRun: 01\t Epoch: 790\t Loss: 0.2477\t Train: 86.74%\t Valid: 81.72%\tTest: 74.31%\nRun: 01\t Epoch: 800\t Loss: 0.2509\t Train: 86.80%\t Valid: 82.02%\tTest: 75.45%\nModel saved.\nRun: 01\t Epoch: 810\t Loss: 0.3153\t Train: 77.73%\t Valid: 73.51%\tTest: 64.93%\nRun: 01\t Epoch: 820\t Loss: 0.2882\t Train: 81.21%\t Valid: 77.56%\tTest: 70.79%\nRun: 01\t Epoch: 830\t Loss: 0.2742\t Train: 83.13%\t Valid: 79.52%\tTest: 72.20%\nRun: 01\t Epoch: 840\t Loss: 0.2721\t Train: 83.62%\t Valid: 79.80%\tTest: 73.53%\nRun: 01\t Epoch: 850\t Loss: 0.2631\t Train: 84.71%\t Valid: 80.65%\tTest: 73.46%\nRun: 01\t Epoch: 860\t Loss: 0.2647\t Train: 84.72%\t Valid: 80.08%\tTest: 73.14%\nRun: 01\t Epoch: 870\t Loss: 0.2586\t Train: 85.39%\t Valid: 80.89%\tTest: 74.35%\nRun: 01\t Epoch: 880\t Loss: 0.2536\t Train: 85.94%\t Valid: 81.16%\tTest: 73.68%\nRun: 01\t Epoch: 890\t Loss: 0.2553\t Train: 85.85%\t Valid: 81.38%\tTest: 74.66%\nRun: 01\t Epoch: 900\t Loss: 0.2558\t Train: 85.73%\t Valid: 81.29%\tTest: 73.72%\nRun: 01\t Epoch: 910\t Loss: 0.2554\t Train: 85.70%\t Valid: 81.56%\tTest: 73.63%\nRun: 01\t Epoch: 920\t Loss: 0.2507\t Train: 86.25%\t Valid: 81.74%\tTest: 74.09%\nRun: 01\t Epoch: 930\t Loss: 0.2483\t Train: 86.60%\t Valid: 81.88%\tTest: 75.40%\nRun: 01\t Epoch: 940\t Loss: 0.2636\t Train: 84.95%\t Valid: 80.21%\tTest: 73.54%\nRun: 01\t Epoch: 950\t Loss: 0.2542\t Train: 85.81%\t Valid: 81.41%\tTest: 74.25%\nRun: 01\t Epoch: 960\t Loss: 0.2484\t Train: 86.44%\t Valid: 82.07%\tTest: 75.06%\nRun: 01\t Epoch: 970\t Loss: 0.2499\t Train: 86.74%\t Valid: 82.30%\tTest: 75.22%\nRun: 01\t Epoch: 980\t Loss: 0.2477\t Train: 86.93%\t Valid: 82.22%\tTest: 75.43%\nRun: 01\t Epoch: 990\t Loss: 0.2438\t Train: 87.09%\t Valid: 82.44%\tTest: 75.46%\nModel saved.\nRun: 01\t Epoch: 1000\t Loss: 0.2758\t Train: 83.92%\t Valid: 79.69%\tTest: 70.74%\nRun 01:\nHighest Train: 87.09\nHighest Valid: 82.44\n  Final Train: 87.09\n   Final Test: 75.46\nAll runs:\nHighest Train: 87.09 ± nan\nHighest Valid: 82.44 ± nan\n  Final Train: 87.09 ± nan\n   Final Test: 75.46 ± nan\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(humanize.naturaldelta(start_time - time.time()))","execution_count":20,"outputs":[{"output_type":"stream","text":"an hour\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}